defaults:
  - _self_
  - dset: musdb44
  - svd: default
  - variant: default
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog

dummy:
dset:
  musdb: 
  musdb_samplerate: 16000
  use_musdb: false   # set to false to not use musdb as training data.
  wav:  /home/ps/xxn/data/dereverberation
  wav2:  # second custom wav dataset
  segment: 10
  shift: 1
  train_valid: false
  full_cv: true
  samplerate: 16000   # 修改为16kHz匹配音频文件
  channels: 1         # 修改为单声道匹配音频文件
  normalize: true
  metadata: ./metadata
  sources: ['dry', 'rir']
  valid_samples: # valid dataset size
  backend: null   # if provided select torchaudio backend.

test:
  save: True # False
  best: True
  workers: 0  # 禁用多进程评估
  every: 50   # 减少评估频率，避免频繁卡住
  split: true
  shifts: 1
  overlap: 0.25
  sdr: false  # 禁用复杂的SDR计算，只使用快速的NSDR
  metric: 'loss'  # metric used for best model selection on the valid set, can also be nsdr
  nonhq:   # path to non hq MusDB for evaluation

epochs: 5
batch_size: 64
max_batches:  # limit the number of batches per epoch, useful for debugging
              # or if your dataset is gigantic.
optim:
  lr: 1e-3  # 3e-4，# 提高学习率
  momentum: 0.9
  beta2: 0.999
  loss: l1    # l1 or mse
  optim: adam
  weight_decay: 0
  clip_grad: 5.0    # 0，添加梯度裁剪，防止梯度爆炸

# 新增：去混响专用损失配置
dereverberation_loss:
  enable: true                    # 是否启用专用去混响损失,ll
  dry_weight: 3.0                # 干声权重
  rir_weight: 1.0                # RIR权重  
  time_weight: 1.0               # 时域损失权重
  freq_weight: 0.5               # 频域损失权重
  mel_weight: 0.3                # 感知损失权重
  consistency_weight: 0.2        # 一致性损失权重
  rir_reg_weight: 0.1           # RIR正则化权重
  time_loss_type: "l1"          # 时域损失类型: l1, mse, huber
  use_time_domain_conv: false   # 使用FFT卷积（推荐），时域卷积仅用于验证
  n_fft: 1024                   # STFT参数
  n_mels: 80                    # Mel频谱参数
  sr: 16000

# 新增：去混响专用评估指标配置  
dereverberation_metrics:
  enable: true                   # 是否启用专用评估指标
  compute_pesq: true            # 计算PESQ估算
  compute_stoi: true            # 计算STOI估算
  compute_rt60: true            # 计算混响时间误差

seed: 42
debug: false
valid_apply: true
flag:
save_every:
weights: [3., 1.]  # 干声权重更高，因为去混响主要目标是恢复干声

augment:
  shift_same: false
  repitch:
    proba: 0.0    # 去混响不需要音高变化 原值0.2
    max_tempo: 12
  remix:
    proba: 0.0    # 去混响不需要remix 原值1
    group_size: 4
  scale:
    proba: 0.5    # 降低音量缩放概率 原值1
    min: 0.8      # 缩小缩放范围，保持更真实 原值0.25
    max: 1.2      # 原值1.25
    # proba: 0.8    # 降低音量缩放概率 原值1
    # min: 0.85     # 缩小缩放范围，保持更真实 原值0.25
    # max: 1.15     # 原值1.25
  flip: false     # 去混响通常不需要翻转 原值true

continue_from:  # continue from other XP, give the XP Dora signature.
continue_pretrained:   # signature of a pretrained XP, this cannot be a bag of models.
pretrained_repo:   # repo for pretrained model (default is official AWS)
continue_best: true
continue_opt: false

misc:
  num_workers: 10
  num_prints: 4
  show: false
  verbose: false

# List of decay for EMA at batch or epoch level, e.g. 0.999.
# Batch level EMA are kept on GPU for speed.
ema:
  epoch: []
  batch: []

use_train_segment: true  # to remove
model_segment:  # override the segment parameter for the model, usually 4 times the training segment.
model: htdemucs  # see demucs/train.py for the possibilities, and config for each model hereafter.
demucs:  # see demucs/demucs.py for a detailed description
  # Channels
  channels: 64
  growth: 2
  # Main structure
  depth: 6
  rewrite: true
  lstm_layers: 0
  # Convolutions
  kernel_size: 8
  stride: 4
  context: 1
  # Activations
  gelu: true
  glu: true
  # Normalization
  norm_groups: 4
  norm_starts: 4
  # DConv residual branch
  dconv_depth: 2
  dconv_mode: 1  # 1 = branch in encoder, 2 = in decoder, 3 = in both.
  dconv_comp: 4
  dconv_attn: 4
  dconv_lstm: 4
  dconv_init: 1e-4
  # Pre/post treatment
  resample: true
  normalize: false
  # Weight init
  rescale: 0.1

hdemucs:  # see demucs/hdemucs.py for a detailed description
  # Channels
  channels: 48
  channels_time:
  growth: 2
  # STFT
  nfft: 4096
  wiener_iters: 0
  end_iters: 0
  wiener_residual: false
  cac: true
  # Main structure
  depth: 6
  rewrite: true
  hybrid: true
  hybrid_old: false
  # Frequency Branch
  multi_freqs: []
  multi_freqs_depth: 3
  freq_emb: 0.2
  emb_scale: 10
  emb_smooth: true
  # Convolutions
  kernel_size: 8
  stride: 4
  time_stride: 2
  context: 1
  context_enc: 0
  # normalization
  norm_starts: 4
  norm_groups: 4
  # DConv residual branch
  dconv_mode: 1
  dconv_depth: 2
  dconv_comp: 4
  dconv_attn: 4
  dconv_lstm: 4
  dconv_init: 1e-3
  # Weight init
  rescale: 0.1

# Torchaudio implementation of HDemucs
torch_hdemucs:
# Channels
  channels: 48
  growth: 2
  # STFT
  nfft: 4096
  # Main structure
  depth: 6
  freq_emb: 0.2
  emb_scale: 10
  emb_smooth: true
  # Convolutions
  kernel_size: 8
  stride: 4
  time_stride: 2
  context: 1
  context_enc: 0
  # normalization
  norm_starts: 4
  norm_groups: 4
  # DConv residual branch
  dconv_depth: 2
  dconv_comp: 4
  dconv_attn: 4
  dconv_lstm: 4
  dconv_init: 1e-3

htdemucs:  # see demucs/htdemucs.py for a detailed description
  # Channels
  channels: 48
  channels_time:
  growth: 2
  # STFT (对16kHz采样率，2048更合适) 原值4096
  nfft: 2048
  # # STFT - 保持4096以确保时频域维度匹配，即使对16kHz也能工作
  # nfft: 4096
  wiener_iters: 0
  end_iters: 0
  wiener_residual: false
  cac: true
  # Main structure
  depth: 4
  # depth: 6                 # 增加深度，从4增加到6，提升模型表达能力
  rewrite: true
  # Frequency Branch
  multi_freqs: []
  multi_freqs_depth: 3
  freq_emb: 0.2
  emb_scale: 10
  emb_smooth: true
  # Convolutions
  kernel_size: 8
  stride: 4
  time_stride: 2
  context: 1
  context_enc: 0
  # normalization
  norm_starts: 4
  norm_groups: 4
  # DConv residual branch
  dconv_mode: 1
  dconv_depth: 2
  dconv_comp: 8
  dconv_init: 1e-3
  # Before the Transformer
  bottom_channels: 0
  # CrossTransformer
  # ------ Common to all
  # Regular parameters
  t_layers: 5
  t_hidden_scale: 4.0
  t_heads: 8
  t_dropout: 0.0
  t_layer_scale: True
  t_gelu: True
  # ------------- Positional Embedding
  t_emb: sin
  t_max_positions: 10000 # for the scaled embedding
  t_max_period: 10000.0 
  t_weight_pos_embed: 1.0
  t_cape_mean_normalize: True
  t_cape_augment: True
  t_cape_glob_loc_scale: [5000.0, 1.0, 1.4]
  t_sin_random_shift: 0
  # ------------- norm before a transformer encoder
  t_norm_in: True
  t_norm_in_group: False
  # ------------- norm inside the encoder
  t_group_norm: False
  t_norm_first: True
  t_norm_out: True
  # ------------- optim
  t_weight_decay: 0.0
  t_lr:
  # ------------- sparsity
  t_sparse_self_attn: False
  t_sparse_cross_attn: False
  t_mask_type: diag
  t_mask_random_seed: 42
  t_sparse_attn_window: 400
  t_global_window: 100
  t_sparsity: 0.95
  t_auto_sparsity: False
  # Cross Encoder First (False)
  t_cross_first: False
  # Weight init
  rescale: 0.1

svd:  # see svd.py for documentation
  penalty: 0
  min_size: 0.1
  dim: 1
  niters: 2
  powm: false
  proba: 1
  conv_only: false
  convtr: false
  bs: 1

quant:  # quantization hyper params
  diffq:    # diffq penalty, typically 1e-4 or 3e-4
  qat:      # use QAT with a fixed number of bits (not as good as diffq)
  min_size: 0.2
  group_size: 8

dora:
  dir: outputs
  exclude: ["misc.*", "slurm.*", 'test.reval', 'flag', 'dset.backend']

slurm:
  time: 4320
  constraint: volta32gb
  setup: ['module load cudnn/v8.4.1.50-cuda.11.6 NCCL/2.11.4-6-cuda.11.6 cuda/11.6']

# Hydra config
hydra:
  job_logging:
    formatters:
      colorlog:
        datefmt: "%m-%d %H:%M:%S"
